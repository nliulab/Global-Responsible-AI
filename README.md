
# 🌍 Global Responsible AI Landscape: A Comprehensive Guide

Welcome to the **Global Responsible AI Landscape** repository! This repository is a curated collection of guidelines, policies, research institutes, and tools related to the development and deployment of Responsible AI around the world. Our goal is to provide an organized and narrative-rich resource that bridges technical, ethical, and governance aspects of AI.

## 📌 Why This Repository?

The rapid advancement of AI technologies has brought immense opportunities and challenges. Ensuring responsible AI requires:

- **Robust Guidelines & Frameworks**: Frameworks to guide AI development and deployment.
- **Effective Policies**: Governance structures to regulate AI use ethically and equitably.
- **Collaborative Research**: Institutes and organizations leading the way in RAI initiatives.

This repository goes beyond simple listings to offer contextual narratives that explain the importance and application of each resource.

## 🗂️ Categories

### 1. Reporting Guidelines & Governance Frameworks
These guidelines standardize how AI models are described, making research reproducible and results trustworthy.

### Legend
- 🧩 **Governance Framework**: Refers to a structured system or methodology designed to guide the development, evaluation, or deployment of AI systems. Frameworks often provide overarching principles, strategies, and actionable steps for specific use cases.
- 📜 **Reporting Guideline**: Represents a set of recommended practices or standards for reporting, evaluating, or governing AI systems. Guidelines are typically more focused on ensuring quality, transparency, and accountability.

---

### Prediction Models
> **Note**: These works are MAINLY focusing on prediction models

- 🧩 **[ABCDS Framework](https://aihealth.duke.edu/algorithm-based-clinical-decision-support-abcds/):** ABCDS (Accountability, Bias, Consistency, Decision-support, and Safety) provides a structured approach for the oversight and deployment of AI prediction models in local healthcare settings. It emphasizes monitoring model performance, addressing potential biases, and ensuring safety and quality in real-world applications. This framework guides organizations in achieving reliable, ethical, and patient-centered AI integration.
- 🧩 **[CHAI](https://chai.org/assurance-standards-guide/):** CHAI (Coalition for Health AI) creates a framework to ensure trustworthy AI adoption in healthcare by addressing health impact, fairness, ethics, and equity principles. This initiative unites experts from healthcare systems, academia, government, and industry to establish assurance standards, reporting practices, and governance guidelines for equitable and responsible AI integration. While CHAI appears to be developing a Generative AI version, we are focusing on its application in prediction models.
- 📜 **[CLAIM](https://pubs.rsna.org/doi/10.1148/ryai.2020200029):** CLAIM (Checklist for Artificial Intelligence in Medical Imaging) is designed to guide the reporting of AI applications in medical imaging, including classification, image reconstruction, and workflow optimization. Modeled after established standards like STARD, it provides best practices for authors and reviewers to ensure clarity, reproducibility, and rigor in scientific communication. CLAIM emphasizes structured reporting of methodology, data handling, and model performance to support transparent and high-quality research in medical imaging.
- 🧩 **[DECIDE-AI](https://www.ideal-collaboration.net/projects/decide-ai/):** DECIDE-AI (Developmental Evaluation and Clinical Integration Decision-support Evaluation for Artificial Intelligence) is a framework for evaluating and reporting early-stage decision-support AI systems in healthcare. It provides structured guidance to ensure these systems meet standards for usability, clinical integration, and patient safety during their development, fostering trust and reliability in real-world applications.
- 📜 **[FUTURE-AI](https://future-ai.eu):** FUTURE-AI (Fairness, Universality, Traceability, Usability, Robustness, and Explainability) is an international consensus guideline for trustworthy AI in healthcare. Developed by a global consortium of interdisciplinary experts, it provides 30 best practices addressing technical, clinical, ethical, and legal dimensions of AI development, validation, and deployment. FUTURE-AI emphasizes risk-informed strategies across six guiding principles to ensure AI tools are safe, effective, and trusted in clinical settings.
- 📜 **[HEAAL Framework](https://healthaipartnership.org/health-equity-across-the-ai-lifecycle-heaal):** HEAAL (Health Equity Across the AI Lifecycle) assesses the impact of AI solutions on health equity across five domains—accountability, fairness, fitness for purpose, reliability and validity, and transparency—at eight key decision points. It provides healthcare organizations with step-by-step procedures to mitigate risks and ensure inclusive, equitable AI adoption.
- 📜 **[PROBAST-AI](https://www.probast.org):** PROBAST-AI (Prediction Model Risk of Bias Assessment Tool for Artificial Intelligence) is designed to assess the risk of bias and applicability in AI prediction models, particularly in healthcare. It helps identify potential pitfalls in study design or data use, enhancing the credibility and reliability of AI-driven conclusions.
- 📜 **[TRIPOD+AI](https://www.tripod-statement.org):** TRIPOD-AI (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis for Artificial Intelligence) is an adaptation of the TRIPOD framework for AI prediction models. It provides clarity on the development, validation, and testing processes, facilitating peer review and supporting future applications in healthcare.
- 📜 **[STARD-AI](https://bmjopen.bmj.com/content/11/6/e047709):** STARD-AI (Standards for Reporting of Diagnostic Accuracy Studies for Artificial Intelligence) focuses on diagnostic AI studies, providing clear standards for transparent reporting. By improving reproducibility and reliability, it ensures diagnostic tools are accurately evaluated and compared, supporting better clinical decision-making.

### Large Language Models (LLMs)
- 📜 **[CANGARU](https://arxiv.org/abs/2307.08974):** CANGARU (ChatGPT and Artificial Intelligence Natural Large Language Models for Accountable Reporting and Use) establishes reporting guidelines for the responsible use of large language models (LLMs) like ChatGPT in academic research and scientific writing. Developed by a multidisciplinary team, it promotes consensus on transparency, accountability, and consistency, while preventing fragmented or conflicting regulations.
- 📜 **[CHART](https://bmjopen.bmj.com/content/14/5/e081155):** CHART (Chatbot Assessment Reporting Tool) provides structured reporting standards for evaluating the performance of LLM-linked chatbots, such as ChatGPT, in providing clinical advice. Developed by a multidisciplinary team and registered with the EQUATOR network, it ensures transparency and consistency in studies on chatbot accuracy for diagnosis, treatment, and prevention, benefiting researchers, clinicians, and patients.



### 2. Governance Policies
Governance policies align technological advancements with societal values, ensuring accountability, fairness, and inclusivity.

- **[European Union AI Act](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)**: The EU AI Act aims to create a comprehensive legal framework that manages risks while ensuring the safety and rights of individuals. It categorizes AI systems based on risk levels, mandates compliance measures for high-risk applications, and promotes transparency and accountability. This ensures AI systems can be both innovative and safe for end users.

- **[Singapore IMDA Model AI Governance Framework](https://www.imda.gov.sg)**: Designed as a practical guide for companies, this framework outlines principles and practices for ethical AI use. It emphasizes transparency, accountability, and human-centric design to build trust. By encouraging practical implementation, it helps businesses balance innovation with public confidence in AI systems.

- **[United States NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)**: This framework offers organizations a structured approach to identifying and managing AI-related risks. It prioritizes fairness, adaptability, and explainability while advocating for robust risk assessment practices. Its goal is to create AI systems that are both responsible and effective in their deployment.

- **[WHO Guidance on Ethical AI](https://www.who.int/publications/i/item/9789240029200)**: The WHO's guidance focuses on six principles: protecting autonomy, promoting well-being, ensuring transparency, fostering inclusiveness, holding developers accountable, and encouraging sustainability. These principles are designed to guide the ethical deployment of AI in healthcare, ensuring it improves global health while safeguarding equity and human rights.

- **[WHO Guideline on Large Multimodal Models (LMMs)](https://www.who.int/publications/i/item/9789240084759)**: This guideline outlines ethical and practical considerations for developing and deploying LMMs in healthcare and public health. It addresses mitigating bias, ensuring representativeness, safeguarding privacy, and integrating ethics throughout the AI lifecycle. The aim is to harness LMMs' potential for high-stakes decisions while reducing risks and promoting equitable outcomes.



### 3. Research Institutes
These organizations advance interdisciplinary research and promote best practices.

- **[Responsible AI Network (RAIN)](https://www.industry.gov.au/science-technology-and-innovation/technology/national-artificial-intelligence-centre/responsible-ai-network):** RAN is an initiative supported by Australia's National Artificial Intelligence Centre. It promotes ethical AI development through collaboration with government, industry, and academia. The network focuses on providing resources, training, and certifications to support responsible AI practices and aims to establish benchmarks and guidelines to ensure AI systems are used ethically and equitably.

- **[Duke Institute for Health Innovation (DIHI)](https://dihi.org)**: DIHI accelerates innovative healthcare solutions by integrating advanced technologies, data science, and collaborative initiatives. It provides a platform for testing and implementing novel AI solutions in real-world clinical settings, focusing on enhancing care quality, safety, and equity.

- **[Oxford Institute for Ethics in AI](https://www.oxford-aiethics.ox.ac.uk)**: Combining philosophical inquiry with practical application, this institute explores ethical dilemmas arising from AI technologies. Its work informs both academia and policy-making globally.



### 4. Other Categories/Groups
