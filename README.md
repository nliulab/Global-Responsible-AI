# üåç Global Responsible AI Landscape: A Comprehensive Guide

Welcome to the **Global Responsible AI Landscape** repository! This repository is a curated collection of guidelines, policies, research institutes, and tools related to the development and deployment of Responsible AI around the world. Our goal is to provide an organized and narrative-rich resource that bridges technical, ethical, and governance aspects of AI.

---

## üìå Why This Repository?

The rapid advancement of AI technologies has brought immense opportunities and challenges. Ensuring responsible AI requires:

- **Robust Guidelines & Frameworks**: Frameworks to guide AI development and deployment.
- **Effective Policies**: Governance structures to regulate AI use ethically and equitably.
- **Collaborative Research**: Institutes and organizations leading the way in RAI initiatives.

This repository goes beyond simple listings to offer contextual narratives that explain the importance and application of each resource.

---

## üì¨ Contact Us

We value your input and are here to answer your questions or hear your suggestions!  
Feel free to reach out via [GitHub Issues](https://github.com/nliulab/Global-Responsible-AI/issues).

---

## üåÄ The AI Lifecycle: A Holistic Approach  

The development of AI systems follows a structured lifecycle, encompassing multiple phases from initial ideation to long-term maintenance. Each phase involves specific processes, challenges, and considerations that contribute to the overall quality and impact of the AI system.  

### 1Ô∏è‚É£ Model Development  
This phase involves designing, training, and validating the AI model to achieve specific objectives. Developers select appropriate datasets, define model architectures, and employ training methodologies.  

**Key Considerations**:  
- **Data Quality**: Ensuring datasets are representative, diverse, and unbiased.  
- **Transparency**: Documenting the rationale behind model design choices.  
- **Ethical Issues**: Potential biases embedded in training data, lack of inclusivity, and opacity in decision-making logic.  

### 2Ô∏è‚É£ Evaluation  
Evaluation focuses on testing the AI system under diverse conditions to ensure reliability, robustness, and fairness. This phase includes benchmarking, stress-testing, and assessing the model's generalizability to new environments.  

**Key Considerations**:  
- **Performance Metrics**: Defining metrics that reflect real-world utility and ethical implications.  
- **Reproducibility**: Ensuring results are consistent across different datasets and environments.  
- **Ethical Issues**: Misrepresentation of performance metrics, overfitting, and exclusion of edge cases.  

### 3Ô∏è‚É£ Bias and Risk Assessment  
Bias and risk assessment identifies potential pitfalls in the model's predictions, focusing on fairness, safety, and ethical implications. Developers scrutinize the model for disparities across different demographic groups or unintended consequences.  

**Key Considerations**:  
- **Fairness Metrics**: Evaluating how predictions differ across populations.  
- **Risk Management**: Proactively identifying scenarios that could lead to harm.  
- **Ethical Issues**: Discrimination, inequity, and failure to account for societal impacts.  

### 4Ô∏è‚É£ Implementation  
The implementation phase involves deploying the AI system in real-world settings. This requires integrating the model into workflows, providing user training, and establishing governance mechanisms.  

**Key Considerations**:  
- **Scalability**: Adapting the system to different operational scales and settings.  
- **Accountability**: Assigning clear roles for oversight and error management.  
- **Ethical Issues**: Data privacy, user autonomy, and risks from inappropriate use.  

### 5Ô∏è‚É£ Continuous Monitoring  
Once deployed, the system enters an operational phase where it must be continuously monitored to ensure ongoing performance and ethical compliance. Monitoring includes tracking for data drift, updating models, and incorporating feedback.  

**Key Considerations**:  
- **Performance Tracking**: Ensuring consistent accuracy and relevance over time.  
- **Adaptability**: Updating models to accommodate new data or requirements.  
- **Ethical Issues**: Lack of transparency in updates, neglect of user feedback, and over-reliance on outdated systems.  

---

## üó∫Ô∏è The AI Lifecycle Flow  


---

## üìã Comprehensive Table of Guidelines and Frameworks

| **Name** | **Category** | **Focus Area** | **Description** |
|----------|--------------|----------------|-----------------|
| [ABCDS Framework](https://aihealth.duke.edu/algorithm-based-clinical-decision-support-abcds/) | Prediction Models | Whole Lifecycle | Provides a structured approach for the oversight and deployment of AI prediction models, emphasizing monitoring, safety, and quality in real-world applications. |
| [CHAI](https://chai.org/assurance-standards-guide/) | Research Institute | Trustworthy AI | Unites experts to establish assurance standards and governance guidelines for equitable and responsible AI integration. |
| [CLAIM](https://pubs.rsna.org/doi/10.1148/ryai.2020200029) | Prediction Models | Reporting | Guides reporting of AI applications in medical imaging to ensure clarity and reproducibility. |
| [DECIDE-AI](https://www.ideal-collaboration.net/projects/decide-ai/) | Prediction Models | Evaluation | Framework for evaluating and reporting early-stage decision-support AI systems in healthcare. |
| [FUTURE-AI](https://future-ai.eu) | Prediction Models | Whole Lifecycle | Provides 30 best practices for trustworthy AI in healthcare, addressing technical, clinical, ethical, and legal dimensions. |
| [HEAAL Framework](https://healthaipartnership.org/health-equity-across-the-ai-lifecycle-heaal) | Prediction Models | Health Equity | Assesses the impact of AI solutions on health equity across five domains. |
| [PROBAST-AI](https://www.probast.org) | Prediction Models | Bias Assessment | Tool for assessing the risk of bias and applicability in AI prediction models. |
| [TRIPOD+AI](https://www.tripod-statement.org) | Prediction Models | Prognosis/Diagnosis | Provides clarity on the development and validation of AI prediction models. |
| [STARD-AI](https://bmjopen.bmj.com/content/11/6/e047709) | Prediction Models | Reporting Standards | Focuses on diagnostic AI studies, ensuring reproducibility and reliability. |
| [CANGARU](https://arxiv.org/abs/2307.08974) | LLMs | Reporting | Establishes guidelines for responsible use of LLMs like ChatGPT. |
| [CHART](https://bmjopen.bmj.com/content/14/5/e081155) | LLMs | Evaluation | Provides structured reporting standards for evaluating LLM-linked chatbots. |
| [EU AI Act](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai) | Governance Policy | Regulation | Creates a legal framework categorizing AI systems based on risk levels. |
| [Singapore IMDA Model](https://www.imda.gov.sg) | Governance Policy | Ethical AI | Outlines principles for ethical AI use, emphasizing transparency and accountability. |
| [NIST AI RMF](https://www.nist.gov/itl/ai-risk-management-framework) | Governance Policy | Risk Management | Offers a structured approach to identifying and managing AI-related risks. |
| [WHO Ethical AI](https://www.who.int/publications/i/item/9789240029200) | Governance Policy | Healthcare | Guides ethical deployment of AI in healthcare with six principles. |
| [WHO LMMs Guideline](https://www.who.int/publications/i/item/9789240084759) | Governance Policy | LMMs | Provides ethical and practical considerations for large multimodal models. |
| [RAIN](https://www.industry.gov.au/science-technology-and-innovation/technology/national-artificial-intelligence-centre/responsible-ai-network) | Research Institute | Ethical AI | Promotes ethical AI through collaboration with government, academia, and industry. |
| [DIHI](https://dihi.org) | Research Institute | Healthcare | Accelerates innovative healthcare solutions integrating data science and advanced technologies. |
| [Oxford AI Ethics](https://www.oxford-aiethics.ox.ac.uk) | Research Institute | Ethics | Explores ethical dilemmas arising from AI technologies. |
