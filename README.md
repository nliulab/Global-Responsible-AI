
# ðŸŒ Comprehensive Guide to the Global Landscape of Responsible AI

Welcome to the **Global Responsible AI Landscape** repository! This repository is a curated collection of guidelines, policies, research institutes, and tools related to the development and deployment of Responsible AI around the world. Our goal is to provide an organized and narrative-rich resource that bridges technical, ethical, and governance aspects of AI.

## ðŸ“Œ Why This Repository?

The rapid advancement of AI technologies has brought immense opportunities and challenges. Ensuring responsible AI requires:

- **Robust Guidelines**: Frameworks to guide AI development and deployment.
- **Effective Policies**: Governance structures to regulate AI use ethically and equitably.
- **Collaborative Research**: Institutes and organizations leading the way in RAI initiatives.

This repository goes beyond simple listings to offer contextual narratives that explain the importance and application of each resource.

## ðŸ—‚ï¸ Categories

### 1. Reporting Guidelines

Comprehensive frameworks to document and report AI processes and outcomes:

- **[ABCDS Framework](#)**: Provides a structured approach for the oversight and deployment of AI prediction models in local healthcare settings. It emphasizes monitoring model performance, addressing potential biases, and ensuring safety and quality in real-world applications.

- **[CANGARU](#)**: Establishes reporting guidelines for the responsible use of large language models (LLMs) like ChatGPT in academic research and scientific writing. It promotes transparency, accountability, and consistency.

- **[CHAI](#)**: Ensures trustworthy AI adoption in healthcare by addressing health impact, fairness, ethics, and equity principles. It unites experts from healthcare systems, academia, government, and industry.

- **[CHART](#)**: Provides structured reporting standards for evaluating the performance of LLM-linked chatbots in clinical advice.

- **[CLAIM](#)**: Guides the reporting of AI applications in medical imaging, ensuring clarity, reproducibility, and rigor in scientific communication.

- **[DECIDE-AI](#)**: Offers guidance for evaluating and reporting early-stage decision-support AI systems in healthcare.

- **[FUTURE-AI](#)**: Provides 30 best practices addressing technical, clinical, ethical, and legal dimensions of AI development.

- **[HEAAL Framework](#)**: Assesses the impact of AI solutions on health equity across multiple domains and decision points.

- **[PROBAST-AI](#)**: Assesses the risk of bias in AI prediction models, particularly in healthcare.

- **[STARD-AI](#)**: Provides clear standards for transparent reporting of diagnostic AI studies.

- **[TRIPOD-AI](#)**: Facilitates clarity in developing and validating AI prediction models.

> **Narrative**: These guidelines standardize how AI models are described, making research reproducible and results trustworthy.

### 2. Governance Policies

Explore the regulatory frameworks shaping responsible AI development globally:

- **[European Union AI Act](#)**: Creates a legal framework to manage risks and ensure safety and rights.

- **[Singapore IMDA Model AI Governance Framework](#)**: Outlines principles for ethical AI use.

- **[United States NIST AI Risk Management Framework](#)**: Offers a structured approach to AI-related risk management.

- **[WHO Guidance on Ethical AI](#)**: Focuses on protecting autonomy, promoting well-being, and ensuring transparency.

- **[WHO Guideline on Large Multimodal Models (LMMs)](#)**: Addresses ethical and practical considerations for developing and deploying LMMs.

> **Narrative**: Governance policies align technological advancements with societal values, ensuring accountability, fairness, and inclusivity.

### 3. Research Institutes

Institutes pioneering responsible AI research:

- **[Australian Responsible AI Institute (ARAI)](#)**: Promotes ethical AI development in Australia.

- **[Duke Institute for Health Innovation (DIHI)](#)**: Integrates advanced technologies into healthcare for quality and equity improvements.

- **[Oxford Institute for Ethics in AI](#)**: Explores ethical dilemmas in AI technologies to inform policy-making.

> **Narrative**: These organizations advance interdisciplinary research and promote best practices.

### 4. Other Categories/Groups
